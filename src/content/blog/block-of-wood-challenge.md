---
title: 'Why We Mail Every Engineering Candidate a Block of Wood'
description: "We replaced take-home coding assignments with blocks of basswood. Here's why it's the best hiring decision we've ever made."
pubDate: 'Feb 21 2026'
category: 'Culture'
readTime: '8 min read'
author:
  name: 'Dana Osei'
  credential: 'Head of People · sparecycles.ai'
  type: 'human'
---

I want to tell you about the weirdest hiring decision we've ever made, and why we're never going back.

Eighteen months ago, we were drowning in take-home assignments. We'd send out a standard systems design prompt — "build a rate limiter," "design a job queue," that kind of thing — and we'd get back competent, interchangeable submissions. For most of our history, this was merely uninspiring. Then, sometime in late 2023, it became completely useless.

You already know what happened. The submissions didn't get worse. They got eerily, uniformly better. Beautifully commented code. Thoughtful README files. Edge cases handled with a confidence that didn't match the candidate's resume. We started asking ourselves, in hushed tones at first and then pretty openly: *is any of this real?*

To be clear — we are not philosophically opposed to engineers using AI. We're an AI company. We use it ourselves, every day, in ways that would have seemed like science fiction to us three years ago. The problem wasn't that candidates were using it. The problem was that we couldn't tell anything about the candidate from the output anymore. A take-home assignment is supposed to be a window into how someone thinks. We were getting a window into how GPT-4 thinks, with a different name on the cover.

So we did something stupid. Or at least, it sounded stupid when our CTO suggested it at 11pm during a particularly bad hiring debrief.

We started mailing candidates a block of wood.

---

## Who We Are

sparecycles.ai sits at the frontier of human-machine collaboration — we build infrastructure that lets AI systems operate during the moments between human intention and human action. If that sounds vague, it's because what we do is genuinely hard to describe to someone who hasn't seen it. The short version: we work on the edges of what's possible with current models, and we need engineers who are comfortable in territory that doesn't have a map yet.

That context matters for everything that follows.

---

## What We Actually Send

Every candidate who passes our initial recruiter conversation receives a small package in the mail. Inside: a 4×4×6 inch block of basswood, a basic carving tool, and a single sheet of paper with the following instructions:

> *Carve something. It can be anything at all. When you're done, mail it back to us with a short note explaining what you made and why. There are no wrong answers, and we are not evaluating your craftsmanship. We promise.*

That's it. No rubric. No suggested timeline beyond "before your next interview." No clarifying examples. Just wood, a tool, and a lot of white space for them to fill however they choose.

---

## The AI Problem We Were Actually Trying to Solve

Before I explain why the carving works, I want to be honest about something: the AI problem in hiring is not really a cheating problem. Framing it that way leads you to bad solutions — plagiarism detectors, proctored coding environments, trick questions designed to "catch" AI usage. We went down some of those roads. They felt adversarial and they didn't work.

The real problem is a *signal* problem. A take-home assignment is valuable because it shows you how someone approaches an open-ended problem over time, alone, without coaching. What decisions do they make? What do they prioritize? What do they ignore? That's the data you're trying to collect. When a language model mediates the whole process, you lose that data. You're not hiring the candidate anymore; you're hiring a very averaged, very smooth version of the internet's collective judgment about what good code looks like.

And averaged, smooth, and collectively-judged is not what you want on a team working at the frontier. You want someone with a genuine point of view. Someone who has developed instincts, not just the ability to retrieve consensus.

The wood carving solves this not because AI can't help with it — you could absolutely ask Claude what to carve — but because the physical execution is irreducibly personal. You still have to pick up the tool. You still have to decide what to make. You still have to sit with the discomfort of being bad at something unfamiliar. No model can do that part for you.

What you make is yours. The note you write is yours. And increasingly, in a hiring landscape where the written and coded artifacts people produce are impossible to attribute with confidence, *yours* is the hardest thing to find.

---

## Why This Works

**We learn how they handle ambiguity.** Some candidates email us asking clarifying questions before they start — what kind of thing are you looking for, how much time should I spend, does it need to be functional? That's useful information. Some just dive in. Some overthink it into paralysis and never send anything back. All of that is signal. At sparecycles, you will regularly be handed problems that are less defined than this one. We need to know which kind of person you are before you get here.

**We learn what they find worth making.** Someone who carves a tiny server rack is telling us something. So is someone who carves a duck, or a hand, or a letter from their name, or a small abstract shape they can't quite describe. We've gotten all of these. Every one of them started a better conversation than any rate limiter implementation ever did.

**We learn how they explain their thinking.** The note that comes with the carving is half the assignment. Is it a sentence? Three paragraphs? Do they apologize for the quality of the carving, or do they own it? Do they explain what they were going for even if they didn't quite get there? Do they have a sense of humor about it? We have hired people largely on the strength of their note.

And yes — we know the note could be written with AI assistance. Some of them probably are. But here's the thing: the note has to describe the actual physical object sitting in front of us. It has to be specific. It has to be accountable to something real. You can't hallucinate a carving. The artifact anchors the explanation in a way that a code submission never could, because code is already abstract. Wood is not.

**We learn if they actually want the job.** This is the one nobody talks about but everyone feels. Sitting down and doing something physical and time-consuming for a company you've only spoken to once is an act of commitment. It takes longer than running a prompt. It requires you to make decisions in private, with no feedback loop, just because you thought it was worth doing. That quality — caring enough to try something uncomfortable — is not easy to screen for. This screens for it.

---

## What We've Learned From the Submissions

We've now received 94 carvings over the past eighteen months. Some observations:

The best engineers, in our experience, do not necessarily produce the best carvings. We have one staff engineer who sent back something that looked like it had been attacked rather than carved, accompanied by a three-paragraph note so self-aware and thoughtful that we moved him to final rounds immediately. We have another whose carving was genuinely beautiful — a small fish, smoothly finished — but whose note revealed someone who wanted to be evaluated and validated at every step. She did not move forward.

The candidates who ask the most clarifying questions up front tend to ask good questions throughout the interview process. This has held up as a pattern.

Almost nobody carves something abstract. People default to objects, animals, and symbols. We've gotten one truly abstract piece — just a set of angular planes that caught the light interestingly — and we hired that person.

The note always matters more than the object. Always.

---

## What About the Technical Evaluation?

Fair question, and I want to address it directly: we did not throw away technical evaluation. We still do a systems design conversation and a live coding session. We review GitHub profiles and ask about past projects in depth. We haven't decided that craftsmanship in woodworking is a proxy for craftsmanship in code.

What we've decided is that the take-home coding assignment, specifically, is no longer doing the job it was designed to do — and that the job it was designed to do (reveal something true about a person's thinking) can be done better, in the current moment, with a different kind of problem. One that AI can advise on but cannot complete. One where the work is physical and therefore undeniably personal. One that, honestly, people seem to find more interesting than yet another API project.

We've heard from more than a few candidates that the carving was the most memorable part of any interview process they'd been through. That it made them actually stop and think about whether they wanted the job. At a frontier AI company, where the work is genuinely strange and the roadmap changes every time a new model drops, we want people who've already asked themselves that question seriously.

---

## The Objections

We've heard them all, and we take them seriously.

*"This disadvantages candidates without workspace or tools."* It does. We include basic tools in the package so no one needs to own anything, and we explicitly invite candidates who can't complete the carving for any reason to write us instead about what they *would* have made and why. About 8% of candidates take this option. Their written responses are evaluated the same way.

*"This disadvantages candidates with physical disabilities."* Same answer. We say this explicitly in the instructions. No one should feel excluded for a reason outside their control.

*"This disadvantages international candidates."* We've had to get creative with customs documentation for some countries, and in a few cases we've offered a digital alternative. It's not perfect. We're working on it.

*"This is just a gimmick."* Maybe. But our 18-month retention rate for engineers hired through this process is 94%, compared to 71% for the two years prior. We'll take the gimmick.

*"You're just doing this because you're scared of AI."* We work on AI for a living. We are not scared of it. We are, however, clear-eyed about what it changes — and what it changes about hiring is something we take seriously enough to do something genuinely weird about.

---

## One More Thing

Every carving we receive goes on a shelf in our office. We have 94 of them now. They take up most of one wall. When people visit — investors, researchers, the occasional journalist trying to figure out what we actually do — they always ask about it, and we get to tell them that each one represents a person who thought it was worth their time to try something unfamiliar and a little ridiculous because they wanted to work here.

In an era when so much of what we produce can be generated, smoothed, optimized, and averaged — when it's genuinely hard to know what came from a person and what came from a model — there's something we find important about having a room full of things that are unambiguously, irreducibly human. Lopsided and overworked and occasionally unidentifiable, but real.

That wall is the best thing in our office. It has nothing to do with AI and everything to do with why this company works.

---

*sparecycles.ai is hiring across engineering, research, and infrastructure. There's a block of wood in it for you.*

*[View open roles →](spacecycles.ai/careers)*
